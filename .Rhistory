??ISLR
??ISLR2
?ISLR2
library(ISLR2)
??ISLR2
?Default
library(effects) # plotting effects
library(tidyverse)
library(caret)
library(gridExtra) # arrange ggplots
library(rsample)
# split the data randomly into training and test
split = initial_split(Default, prop = .7) # 70% training, 30% testing
train = training(split)
test = testing(split)
# split the data randomly into training and test
set.seed(1234)
split = initial_split(Default, prop = .7) # 70% training, 30% testing
train = training(split)
test = testing(split)
# fit logistic regression models
mod_log <- glm(default ~ student + balance + income, family = "binomial",
data = train)
summary(mod_log)
mod_inter <- glm(default ~ student*balance*income, family = "binomial",
data = train)
summary(mod_inter)
# do backward selection with model that has all pairwise combination
mod_step <- step(mod_inter, direction = "backward")
summary(mod_step)
View(train)
# interaction model
mod_inter <- glm(default ~ student*balance*income, family = "binomial",
data = train)
summary(mod_inter)
# do backward selection with model that has all pairwise combination
mod_step <- step(mod_inter, direction = "backward")
summary(mod_step)
reg_logistic <- train(
default ~ student*balance*income,
train,
preProc = c("center", "scale", "zv"),
method = "glmnet",
family = "binomial", # for logistic model, add this parameter; for OLS, remove it
trControl = trainControl(
method = "cv"
)
)
?tuneLength
?train
reg_logistic
reg_logistic$results
reg_logistic$bestTune
reg_logistic$results
summary(reg_logistic)
# find coefficients
coef(reg_logistic$finalModel)
reg_logistic$finalModel
# find coefficients
coef(reg_logistic$finalModel, reg_logistic$finalModel$lambdaOpt)
reg_logistic$finalModel$tuneValue
reg_logistic$finalModel$param
reg_logistic$finalModel$beta
reg_logistic$finalModel$xNames
test = test %>% mutate(pred_log = predict(mod_log, newdata = test, type = "response"),
pred_inter = predict(mod_inter, newdata = test, type = "response"),
pred_step = predict(mod_step, newdata = test, type= "response"))
# reg_logistic is fitted using the 'train' function and is different
predict(reg_logistic, newdata = test, type = "prob")
# reg_logistic is fitted using the 'train' function and is different
predict(reg_logistic, newdata = test, type = "prob") %>% head()
# reg_logistic is fitted using the 'train' function and is different
predict(reg_logistic, newdata = test, type = "prob") %>% select(Yes)
test = test %>% mutate(pred_log = predict(mod_log, newdata = test, type = "response"),
pred_inter = predict(mod_inter, newdata = test, type = "response"),
pred_step = predict(mod_step, newdata = test, type= "response"),
predict(reg_logistic, newdata = test, type = "prob") %>% select(Yes))
View(test)
test = test %>% mutate(pred_log = predict(mod_log, newdata = test, type = "response"),
pred_inter = predict(mod_inter, newdata = test, type = "response"),
pred_step = predict(mod_step, newdata = test, type= "response"),
pred_reg = predict(reg_logistic, newdata = test, type = "prob") %>% select(Yes))
test = test %>% mutate(pred_log = predict(mod_log, newdata = test, type = "response"),
pred_inter = predict(mod_inter, newdata = test, type = "response"),
pred_step = predict(mod_step, newdata = test, type= "response"),
pred_reg = predict(reg_logistic, newdata = test, type = "prob")$Yes)
test = test %>% mutate(pred_log = predict(mod_log, newdata = test, type = "response"),
pred_inter = predict(mod_inter, newdata = test, type = "response"),
pred_step = predict(mod_step, newdata = test, type= "response"),
pred_reg = predict(reg_logistic, newdata = test, type = "prob")$Yes)
View(test)
test %>% select(-Yes)
View(test)
test <- test %>% select(-Yes)
head(test)
# find boxplot of prob predictions versus observed outcomes
ggplot(test) +
aes(x = default, y = pred_add) +
geom_boxplot()
# find boxplot of prob predictions versus observed outcomes
ggplot(test) +
aes(x = default, y = pred_log) +
geom_boxplot()
# find boxplot of prob predictions versus observed outcomes
ggplot(test) +
aes(x = default, y = pred_log) +
geom_point()
View(test)
# find boxplot of prob predictions versus observed outcomes
ggplot(test) +
aes(x = default, y = pred_log) +
geom_boxplot()
ggplot(test) +
aes(x = default, y = pred_inter) +
geom_boxplot()
ggplot(test) +
aes(x = default, y = pred_inter) +
geom_boxplot()
ggplot(test) +
aes(x = default, y = pred_step) +
geom_boxplot()
ggplot(test) +
aes(x = default, y = reg_logistic) +
geom_boxplot()
ggplot(test) +
aes(x = default, y = pred_reg) +
geom_boxplot()
ggplot(test) +
aes(x = default, y = pred_step) +
geom_boxplot()
ggplot(test) +
aes(x = default, y = pred_reg) +
geom_boxplot()
source('~/R/Workshop/PredictiveModeling/PreModWorkshop1_logistic.R', echo=TRUE)
def.off()
dev.off()
ggplot(test) +
aes(x = default, y = pred_reg) +
geom_boxplot()
dev.off()
ggplot(test) +
aes(x = default, y = pred_reg) +
geom_boxplot()
test %>% group_by(default) %>% summarize(avg_pred = mean(pred_log),
sd_pred = sd(pred-Log))
test %>% group_by(default) %>% summarize(avg_pred = mean(pred_log),
sd_pred = sd(pred_Log))
test %>% group_by(default) %>% summarize(avg_pred = mean(pred_log),
sd_pred = sd(pred_log))
test %>% group_by(default) %>% summarize(avg_pred = mean(pred_inter),
sd_pred = sd(pred_inter))
test %>% group_by(default) %>% summarize(avg_pred = mean(pred_step),
sd_pred = sd(pred_step))
test %>% group_by(default) %>% summarize(avg_pred = mean(pred_reg),
sd_pred = sd(pred_reg))
# find these predicted outcomes given the
# predicted probabilities of default
ifelse(test$pred_log < 0.5, "Yes", "No")
# find these predicted outcomes given the
# predicted probabilities of default
out_log = factor(ifelse(test$pred_log < 0.5, "Yes", "No"))
out_inter = factor(ifelse(test$pred_inter < 0.5, "Yes", "No"))
out_step = factor(ifelse(test$pred_step < 0.5, "Yes", "No"))
out_reg = factor(ifelse(test$pred_reg < 0.5, "Yes", "No"))
# find these predicted outcomes given the
# predicted probabilities of default
out_log = factor(ifelse(test$pred_log < 0.5, "Yes", "No"))
# I can compare my predictions against the outcomes
?confusionMatrix()
confusionMatrix(out_log, test$default, positive = "Yes")
"
# find these predicted outcomes given the
# predicted probabilities of default
out_log = factor(ifelse(test$pred_log > 0.5, "Yes", "No"))
out_inter = factor(ifelse(test$pred_inter > 0.5, "Yes", "No"))
out_step = factor(ifelse(test$pred_step > 0.5, "Yes", "No"))
out_reg = factor(ifelse(test$pred_reg > 0.5, "Yes", "No"))
# I can compare my predictions against the outcomes
?confusionMatrix()
confusionMatrix(out_log, test$default, positive = "Yes")
# find these predicted outcomes given the
# predicted probabilities of default
out_log = factor(ifelse(test$pred_log > 0.5, "Yes", "No"))
confusionMatrix(out_log, test$default, positive = "Yes")
confusionMatrix(out_inter, test$default, positive = "Yes")
confusionMatrix(out_reg, test$default, positive = "Yes")
?step
#######
# Practice: using the Boston data
?Boston
data(Boston)
glimpse(Boston)
split <- initial_split(Boston, prop = .7)
train <- training(split)
tset <- testing(split)
set.seed(1234)
split <- initial_split(Boston, prop = .7)
train <- training(split)
tset <- testing(split)
# regularized logistic regression
reg_logistic <- train(
highcrim ~.,
train,
preProc = c("center", "scale", "zv"),
method = "glmnet",
family = "binomial",
trControl = trainControL(
method = "cv",
number = 10
)
)
View(train)
data(Boston)
glimpse(Boston)
# Outcome variable
Boston <- Boston %>%
mutate(highcrim = as.factor(ifelse(crim > median(crim), "yes", "no")))
# Exclude "crim"
Boston <- Boston %>% select(-crim)
# fit a logistic model
mod_log <- glm(highcrim ~., data = train, family = 'binomial')
# set seed
set.seed(1234)
split <- initial_split(Boston, prop = .7)
train <- training(split)
tset <- testing(split)
rm(tset)
# fit a logistic model
mod_log <- glm(highcrim ~., data = train, family = 'binomial')
summary(mod_log)
# regularized logistic regression
reg_logistic <- train(
highcrim ~.,
train,
preProc = c("center", "scale", "zv"),
method = "glmnet",
family = "binomial",
trControl = trainControL(
method = "cv",
number = 10
)
)
# regularized logistic regression
reg_logistic <- train(
highcrim ~.,
train,
preProc = c("center", "scale", "zv"),
method = "glmnet",
family = "binomial",
trControl = trainControl(
method = "cv",
number = 10
)
)
summary(reg_logistic)
summary(reg_logistic$finalModel)
reg_logistic$finalModel
reg_logistic$finalModel$beta
reg_logistic$finalModel$call
reg_logistic$finalModel$
# find variable importance
vip::vip(reg_logistic)
library(vip)
reg_logistic$finalModel$
# find variable importance
vip::vip(reg_logistic)
reg_logistic$finalModel$
# find variable importance
vip(reg_logistic)
reg_logistic$finalModel$
# find variable importance
vip(reg_logistic$modelInfo)
reg_logistic$modelInfo
reg_logistic$results
reg_logistic$bestTune
?vip
# regularized logistic regression
reg_logistic <- train(
highcrim ~.,
train,
preProc = c("center", "scale", "zv"),
method = "glmnet",
family = "binomial",
trControl = trainControl(
method = "cv",
number = 10
)
)
# find variable importance
vip(reg_logistic)
# find variable importance
vip(reg_logistic) %>% summary
# find variable importance
vip(reg_logistic) %>% plot
# find boxplot of prob predictions versus observed outcomes
ggplot(test) +
aes(x = highcrim, y = pred_reg) +
geom_boxplot()
View(test)
test <- testing(split)
View(train)
View(test)
# predict
test = test %>%
mutate(
pred_reg = precit(reg_logistic, newdata = test, type = "prob")$yes,
pred_log = predict(logistic, newdata = test, type = "response"))
# predict
test = test %>%
mutate(
pred_reg = predict(reg_logistic, newdata = test, type = "prob")$yes,
pred_log = predict(logistic, newdata = test, type = "response"))
# predict
test = test %>%
mutate(
pred_reg = predict(reg_logistic, newdata = test, type = "prob")$yes,
pred_log = predict(mod_log, newdata = test, type = "response"))
# find boxplot of prob predictions versus observed outcomes
ggplot(test) +
aes(x = highcrim, y = pred_reg) +
geom_boxplot()
ggplot(test) +
aes(x = highcrim, y = pred_log) +
geom_boxplot()
# convert predicted probabilities to predicted outcomes
ifelse(pred_reg > 0.5, "yes", "no")
# convert predicted probabilities to predicted outcomes
ifelse(test$pred_reg > 0.5, "yes", "no")
# convert predicted probabilities to predicted outcomes
out_reg <- factor(ifelse(test$pred_reg > 0.5, "yes", "no"))
out_log <- factor(ifelse(test$pred_log > 0.5, "yes", "no"))
# compare predicted outcomes ('yes' or 'no')
# against observed outcomes via a confusion matrix
confusionMatrix(out_reg, test$highcrim, positive = "yes")
confusionMatrix(out_log, test$highcrim, positive = "yes")
